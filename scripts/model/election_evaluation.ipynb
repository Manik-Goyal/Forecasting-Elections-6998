{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to a Political Party, drinks may be served!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_2016 import pass_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf \n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import copy\n",
    "from scipy.special import logit\n",
    "from scipy.special import expit\n",
    "\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "\n",
    "from pyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "NaN = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a covariance matrix of size (n, n) with variance sigma2 \n",
    "def cov_matrix(n, sigma2, rho):\n",
    "        m = np.ones(shape=(n,n)) * rho\n",
    "        m2 = np.zeros(shape=(n,n))\n",
    "\n",
    "        np.fill_diagonal(m, 1)\n",
    "        np.fill_diagonal(m2, sigma2 ** .5) \n",
    "    \n",
    "        return(np.matmul(np.matmul(m2, m), m2))\n",
    "\n",
    "def check_cov_matrix(mat, weights):\n",
    "        diag = np.diag(mat)\n",
    "\n",
    "# Fitting RMSE linear regression with hardcoded param values & hyper param values\n",
    "def fit_rmse_day_x(x):\n",
    "        y = []\n",
    "        for num in x:\n",
    "                y.append( 0.03 + (10 **(-6.6)) * (num ** 2) )\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        for i in range(1,N_state_polls+1):\\n                logit_pi_democrat_state[i] = mu_b[state[i], day_state[i]] + mu_c[poll_state[i]] + mu_m[poll_mode_state[i]] +                         mu_pop[poll_pop_state[i]] + unadjusted_state[i] * e_bias[day_state[i]] + raw_measure_noise_state[i] * sigma_measure_noise_state +                                 polling_bias[state[i]]\\n\\n        logit_pi_democrat_national = national_mu_b_average[day_national] +  mu_c[poll_national] + mu_m[poll_mode_national] +                 mu_pop[poll_pop_national] + unadjusted_national * e_bias[day_national] + raw_measure_noise_national * sigma_measure_noise_national +                        national_polling_bias_average\\n        #Likelihood Of the Model\\n        #!need to verify if this is the correct implementation for binomial_logit of stan\\n#       with pyro.plate(\"state-data-plate\", size = N_state_polls):\\n#               pyro.sample(\"n_democrat_state\", dist.Binomial(n_two_share_state, logits = logit_pi_democrat_state), obs = n_democrat_state)\\n\\n#       with pyro.plate(\"national-data-plate\", size = N_national_polls):\\n#               pyro.sample(\"n_democrat_national\", dist.Binomial(n_two_share_national, logits = logit_pi_democrat_national), obs = n_democrat_national)\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model(data):\n",
    "        N_national_polls = data[\"N_national_polls\"] #Number of National Polls\n",
    "        N_state_polls = data[\"N_state_polls\"] #Number of State Polls\n",
    "        T = data[\"T\"] #Number of days\n",
    "        S = data[\"S\"] #Number of states for which at-least 1 poll is available\n",
    "        P = data[\"P\"] #Number of pollsters\n",
    "        M = data[\"M\"] #Number of poll modes\n",
    "        Pop = data[\"Pop\"] #Number of poll populations\n",
    "        state = data[\"state\"] #state index\n",
    "        day_state = data[\"day_state\"] #State Day index\n",
    "        day_national = data[\"day_national\"] #National Day index\n",
    "        poll_state = data[\"poll_state\"] #State Pollster Index\n",
    "        poll_national = data[\"poll_national\"] #National Pollster Index\n",
    "        poll_mode_state = data[\"poll_mode_state\"] #State Poll Mode Index\n",
    "        poll_mode_national = data[\"poll_mode_national\"] #National Poll Model Index\n",
    "        poll_pop_state = data[\"poll_pop_state\"] #State poll population\n",
    "        poll_pop_national = data[\"poll_pop_national\"] #National Poll Populaiton\n",
    "        n_democrat_national = data[\"n_democrat_national\"] #Number of Dem supporters in national poll for a particular poll \n",
    "        n_two_share_national = data[\"n_two_share_national\"] #Total Number of Dem+Reb supporters for a particular poll\n",
    "        n_democrat_state = data[\"n_democrat_state\"] #Number of Dem supporters in state poll for a particular poll\n",
    "        n_two_share_state = data[\"n_two_share_state\"] #Total Number of Dem+Reb supporters for a particular poll\n",
    "        unadjusted_national = data[\"unadjusted_national\"]\n",
    "        unadjusted_state = data[\"unadjusted_state\"]\n",
    "\n",
    "        #Prior Input values\n",
    "        mu_b_prior = data[\"mu_b_prior\"]\n",
    "        state_weights = data[\"state_weights\"]\n",
    "        sigma_c = data[\"sigma_c\"]\n",
    "        sigma_m = data[\"sigma_m\"]\n",
    "        sigma_pop = data[\"sigma_pop\"]\n",
    "        sigma_measure_noise_national = data[\"sigma_measure_noise_national\"]\n",
    "        sigma_measure_noise_state = data[\"sigma_measure_noise_state\"]\n",
    "        sigma_e_bias = data[\"sigma_e_bias\"]\n",
    "\n",
    "        #Covariance Matrix and Scale Input\n",
    "        state_covariance_0 = data[\"state_covariance_0\"]\n",
    "        random_walk_scale = data[\"random_walk_scale\"]\n",
    "        mu_b_T_scale = data[\"mu_b_T_scale\"]\n",
    "        polling_bias_scale = data[\"polling_bias_scale\"]\n",
    "\n",
    "\n",
    "        #Data Transformation\n",
    "        national_cov_matrix_error_sd = torch.sqrt(torch.tensor(state_weights.T @ state_covariance_0 @ state_weights))\n",
    "\n",
    "        #Scale Covariance\n",
    "        ss_cov_poll_bias = torch.tensor((((polling_bias_scale/national_cov_matrix_error_sd)**2).item() * state_covariance_0).values)\n",
    "        ss_cov_mu_b_T = torch.tensor((((mu_b_T_scale/national_cov_matrix_error_sd)**2).item() * state_covariance_0).values)\n",
    "        ss_cov_mu_b_walk = torch.tensor((((random_walk_scale/national_cov_matrix_error_sd)**2).item() * state_covariance_0).values)\n",
    "\n",
    "        #Cholesky Transformation\n",
    "        cholesky_ss_cov_poll_bias = torch.cholesky(ss_cov_poll_bias)\n",
    "        cholesky_ss_cov_mu_b_T = torch.cholesky(ss_cov_mu_b_T)\n",
    "        cholesky_ss_cov_mu_b_walk = torch.cholesky(ss_cov_mu_b_walk)\n",
    "        \n",
    "        with pyro.plate(\"raw_mu_b_T-plate\", size = S):\n",
    "                raw_mu_b_T = pyro.sample(\"mu_b_T\", dist.Normal(0., 1.))\n",
    "#               assert raw_mu_b_T.shape == (S,)\n",
    "\n",
    "        with pyro.plate(\"raw_mu_b_x-asis\", size = S):\n",
    "                with pyro.plate(\"raw_mu_b_y-plate\", size = T):\n",
    "                        raw_mu_b = pyro.sample(\"mu_b_b\", dist.Normal(0., 1.))\n",
    "#                       raw_mu_b.t().flatten() #Matrix to Column Order Vector\n",
    "                        raw_mu_b.transpose(0,1).flatten()\n",
    "\n",
    "        with pyro.plate(\"raw_mu_c-plate\", size = P):\n",
    "                raw_mu_c = pyro.sample(\"raw_mu_c\", dist.Normal(0., 1.))\n",
    "\n",
    "        with pyro.plate(\"raw_mu_m-plate\", size = M):\n",
    "                raw_mu_m = pyro.sample(\"mu_m\", dist.Normal(0., 1.))\n",
    "\n",
    "        with pyro.plate(\"raw_mu_pop-plate\", size = Pop):\n",
    "                raw_mu_pop = pyro.sample(\"raw_mu_pop\", dist.Normal(0., 1.))\n",
    "\n",
    "        #!Not sure if this satisfies Offset=0 and multiplier=0.02\n",
    "        mu_e_bias = pyro.sample(\"mu_e_bias\", dist.Normal(0., 0.02))*0.02\n",
    "\n",
    "        #!Need to find way to add constraint lower = 0, upper = 1\n",
    "        rho_e_bias = pyro.sample(\"rho_e_bias\", dist.Normal(0.7, 0.1))\n",
    "\n",
    "        with pyro.plate(\"raw_e_bias-plate\", size = T):\n",
    "                raw_e_bias = pyro.sample(\"raw_e_bias\", dist.Normal(0., 1.))\n",
    "\n",
    "        with pyro.plate(\"raw_measure_noise_national-plate\", size = N_national_polls):\n",
    "                raw_measure_noise_national = pyro.sample(\"measure_noise_national\", dist.Normal(0., 1.))\n",
    "\n",
    "        with pyro.plate(\"raw_measure_noise_state-plate\", size = N_state_polls):\n",
    "                raw_measure_noise_state = pyro.sample(\"measure_noise_state\", dist.Normal(0., 1.))\n",
    "\n",
    "        with pyro.plate(\"raw_polling_bias-plate\", size = S):\n",
    "                raw_polling_bias = pyro.sample(\"polling_bias\", dist.Normal(0., 1.))\n",
    "\n",
    "        #Transformed Parameters\n",
    "        mu_b = torch.empty(S, T) #initalize mu_b\n",
    "\n",
    "#       mu_b[:,T] = cholesky_ss_cov_mu_b_T.double() @ raw_mu_b_T.double()# + mu_b_prior\n",
    "#       temp = cholesky_ss_cov_mu_b_T.double() @ raw_mu_b_T.double()# + mu_b_prior\n",
    "#       for i in range(1,T):\n",
    "#               mu_b[:, T - i] = cholesky_ss_cov_mu_b_walk @ raw_mu_b[:, T - i] + mu_b[:, T + 1 - i]\n",
    "\n",
    "        mu_c = raw_mu_c * sigma_c\n",
    "        mu_m = raw_mu_m * sigma_m\n",
    "        mu_pop = raw_mu_pop * sigma_pop\n",
    "        sigma_rho = torch.sqrt(1-(rho_e_bias)**2) * sigma_e_bias\n",
    "\n",
    "        e_bias = torch.empty(T) #initalize e_bias\n",
    "#       e_bias[1] = raw_e_bias[1] * sigma_e_bias\n",
    "#       for t in range(2,T+1):\n",
    "#               e_bias[t] = mu_e_bias + rho_e_bias * (e_bias[t - 1] - mu_e_bias) + raw_e_bias[t] * sigma_rho\n",
    "\n",
    "#       polling_bias = cholesky_ss_cov_poll_bias.double() @ raw_polling_bias.double()\n",
    "        national_mu_b_average = mu_b.t() @ state_weights\n",
    "#       national_polling_bias_average = polling_bias.T @ state_weights\n",
    "\n",
    "        logit_pi_democrat_state = torch.empty(N_state_polls)\n",
    "        logit_pi_democrat_national = torch.empty(N_national_polls)\n",
    "        \n",
    "'''\n",
    "        for i in range(1,N_state_polls+1):\n",
    "                logit_pi_democrat_state[i] = mu_b[state[i], day_state[i]] + mu_c[poll_state[i]] + mu_m[poll_mode_state[i]] + \\\n",
    "                        mu_pop[poll_pop_state[i]] + unadjusted_state[i] * e_bias[day_state[i]] + raw_measure_noise_state[i] * sigma_measure_noise_state + \\\n",
    "                                polling_bias[state[i]]\n",
    "\n",
    "        logit_pi_democrat_national = national_mu_b_average[day_national] +  mu_c[poll_national] + mu_m[poll_mode_national] + \\\n",
    "                mu_pop[poll_pop_national] + unadjusted_national * e_bias[day_national] + raw_measure_noise_national * sigma_measure_noise_national +\\\n",
    "                        national_polling_bias_average\n",
    "        #Likelihood Of the Model\n",
    "        #!need to verify if this is the correct implementation for binomial_logit of stan\n",
    "#       with pyro.plate(\"state-data-plate\", size = N_state_polls):\n",
    "#               pyro.sample(\"n_democrat_state\", dist.Binomial(n_two_share_state, logits = logit_pi_democrat_state), obs = n_democrat_state)\n",
    "\n",
    "#       with pyro.plate(\"national-data-plate\", size = N_national_polls):\n",
    "#               pyro.sample(\"n_democrat_national\", dist.Binomial(n_two_share_national, logits = logit_pi_democrat_national), obs = n_democrat_national)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!Need to modify this based on hyper-parameters used by the Original Model\n",
    "def Inference_MCMC(model, data, n_samples = 500, n_warmup = 250, n_chains = 1):\n",
    "        nuts_kernel = NUTS(model)\n",
    "        mcmc = MCMC(nuts_kernel, num_samples = n_samples, warmup_steps = n_warmup, num_chains = n_chains)\n",
    "        mcmc.run(data)\n",
    "        posterior_samples = mcmc.get_samples()\n",
    "\n",
    "        X = posterior_samples[\"mu_b_T\"].t()\n",
    "\n",
    "        X_0 = [x[0].item() for x in X]\n",
    "        X_1 = [x[1].item() for x in X]\n",
    "        X_2 = [x[2].item() for x in X]\n",
    "\n",
    "        \n",
    "        plt.hist(X_0, bins='auto', edgecolor='black', linewidth=0.75)\n",
    "        plt.title(\"mu_b_T\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.hist(X_1, bins='auto', edgecolor='black', linewidth=0.75)\n",
    "        plt.title(\"mu_b_T\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.hist(X_2, bins='auto', edgecolor='black', linewidth=0.75)\n",
    "        plt.title(\"mu_b_T\")\n",
    "        plt.show()\n",
    "\n",
    "        hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}\n",
    "\n",
    "        return posterior_samples, hmc_samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate samples from posterior predictive distribution\n",
    "def sample_posterior_predictive(model, posterior_samples, n_samples, data):\n",
    "        posterior_predictive = Predictive(model, posterior_samples, num_samples = n_samples)\n",
    "        posterior_predictive_samples = posterior_predictive.get_samples(data)\n",
    "\n",
    "        return posterior_predictive_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Quantity from posterior sample\n",
    "def predicted_score(model, posterior_samples, data):\n",
    "        T = data['T']\n",
    "        S = data['S']\n",
    "        posterior_predictive = Predictive(model, posterior_samples)\n",
    "        trace  = posterior_predictive.get_vectorized_trace(data)\n",
    "\n",
    "        mu_b = trace.nodes['mu_b_T']['value']\n",
    "        predicted = torch.empty(S, T)\n",
    "#       for s in range(1,S+1):\n",
    "        for s in range(0,S-2):\n",
    "                predicted[:,s] = expit(mu_b[s,:].t().flatten())\n",
    "\n",
    "        return predicted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we are using the pass_data( ) function from our final_2016.py helper python file in order to abstract the extensive & dull data preprocessing needed before feeding into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016, 'black_pct', 'college_pct', 'hisp_other_pct', 'median_age', 'pct_white_evangel', 'pop_density', 'white_pct', 'wwc_pct'] [0.2162890087639303, 0.00396169583885996, 0.139747908727421, 0.0422148218437831, 30.5, 0.02923107672064036, 9.108415574117505, 0.222308740920812, 0.0250285919948363]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                incvote   R-squared:                       0.770\n",
      "Model:                            OLS   Adj. R-squared:                  0.740\n",
      "Method:                 Least Squares   F-statistic:                     25.15\n",
      "Date:                Mon, 16 Nov 2020   Prob (F-statistic):           1.62e-05\n",
      "Time:                        17:22:43   Log-Likelihood:                -41.736\n",
      "No. Observations:                  18   AIC:                             89.47\n",
      "Df Residuals:                      15   BIC:                             92.14\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     49.6070      0.835     59.386      0.000      47.826      51.387\n",
      "juneapp        0.1393      0.027      5.183      0.000       0.082       0.197\n",
      "q2gdp          0.4480      0.164      2.738      0.015       0.099       0.797\n",
      "==============================================================================\n",
      "Omnibus:                        0.072   Durbin-Watson:                   2.417\n",
      "Prob(Omnibus):                  0.965   Jarque-Bera (JB):                0.289\n",
      "Skew:                          -0.072   Prob(JB):                        0.865\n",
      "Kurtosis:                       2.396   Cond. No.                         34.4\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "model() missing 1 required positional argument: 'polls'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8c03465402f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpass_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: model() missing 1 required positional argument: 'polls'"
     ]
    }
   ],
   "source": [
    "data = pass_data()\n",
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 750/750 [05:48,  2.15it/s, step size=1.12e-01, acc. prob=0.866]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "posterior_samples, hmc_samples = Inference_MCMC(model, data)\n",
    "\n",
    "posterior_predictive_samples = sample_posterior_predictive(model, posterior_samples, 500, data)\n",
    "\n",
    "predicted = predicted_score(model, posterior_samples, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data, polls):\n",
    "    #data from data dictionary\n",
    "\n",
    "    #X\n",
    "    N_national_polls = data[\"N_national_polls\"] #Number of National Polls\n",
    "    N_state_polls = data[\"N_state_polls\"] #Number of State Polls\n",
    "    T = data[\"T\"] #Number of days\n",
    "    S = data[\"S\"] #Number of states for which at-least 1 poll is available\n",
    "    P = data[\"P\"] #Number of pollsters\n",
    "    M = data[\"M\"] #Number of poll modes\n",
    "    Pop = data[\"Pop\"] #Number of poll populations\n",
    "    state = data[\"state\"] #state index\n",
    "    day_state = data[\"day_state\"] #State Day index\n",
    "    day_national = data[\"day_national\"] #National Day index\n",
    "    poll_state = data[\"poll_state\"] #State Pollster Index\n",
    "    poll_national = data[\"poll_national\"] #National Pollster Index\n",
    "    poll_mode_state = data[\"poll_mode_state\"] #State Poll Mode Index\n",
    "    poll_mode_national = data[\"poll_mode_national\"] #National Poll Model Index\n",
    "    poll_pop_state = data[\"poll_pop_state\"] #State poll population\n",
    "    poll_pop_national = data[\"poll_pop_national\"] #National Poll Populaiton\n",
    "    unadjusted_national = data[\"unadjusted_national\"] \n",
    "    unadjusted_state = data[\"unadjusted_state\"] \n",
    "    n_two_share_national = data[\"n_two_share_national\"] #Total Number of Dem+Reb supporters for a particular poll\n",
    "    n_two_share_state = data[\"n_two_share_state\"] #Total Number of Dem+Reb supporters for a particular poll\n",
    "    \n",
    "    #y\n",
    "    if polls is not None:\n",
    "        n_democrat_national = polls[\"n_democrat_national\"] #Number of Dem supporters in national poll for a particular poll \n",
    "        n_democrat_state = polls[\"n_democrat_state\"] #Number of Dem supporters in state poll for a particular poll\n",
    "    else:\n",
    "        n_democrat_national = None\n",
    "        n_democrat_state = None\n",
    "    \n",
    "    #Prior Input values\n",
    "    mu_b_prior = data[\"mu_b_prior\"]\n",
    "    state_weights = data[\"state_weights\"]\n",
    "    sigma_c = data[\"sigma_c\"]\n",
    "    sigma_m = data[\"sigma_m\"]\n",
    "    sigma_pop = data[\"sigma_pop\"]\n",
    "    sigma_measure_noise_national = data[\"sigma_measure_noise_national\"]\n",
    "    sigma_measure_noise_state = data[\"sigma_measure_noise_state\"]\n",
    "    sigma_e_bias = data[\"sigma_e_bias\"]\n",
    "\n",
    "    #Covariance Matrix and Scale Input\n",
    "    state_covariance_0 = data[\"state_covariance_0\"]\n",
    "    random_walk_scale = data[\"random_walk_scale\"]\n",
    "    mu_b_T_scale = data[\"mu_b_T_scale\"]\n",
    "    polling_bias_scale = data[\"polling_bias_scale\"]\n",
    "\n",
    "    #Data Transformation\n",
    "    national_cov_matrix_error_sd = torch.sqrt(torch.tensor(state_weights.T @ state_covariance_0 @ state_weights))\n",
    "\n",
    "    #Scale Covariance\n",
    "    ss_cov_poll_bias = torch.tensor((((polling_bias_scale/national_cov_matrix_error_sd)**2).item() * state_covariance_0).values)\n",
    "    ss_cov_mu_b_T = torch.tensor((((mu_b_T_scale/national_cov_matrix_error_sd)**2).item() * state_covariance_0).values)\n",
    "    ss_cov_mu_b_walk = torch.tensor((((random_walk_scale/national_cov_matrix_error_sd)**2).item() * state_covariance_0).values)\n",
    "\n",
    "    #Cholesky Transformation\n",
    "    cholesky_ss_cov_poll_bias = torch.cholesky(ss_cov_poll_bias)\n",
    "    cholesky_ss_cov_mu_b_T = torch.cholesky(ss_cov_mu_b_T)\n",
    "    cholesky_ss_cov_mu_b_walk = torch.cholesky(ss_cov_mu_b_walk)\n",
    "\n",
    "    #Priors\n",
    "    #Parameters\n",
    "    with pyro.plate(\"raw_mu_b_T-plate\", size = S):\n",
    "        raw_mu_b_T = pyro.sample(\"mu_b_T\", dist.Normal(0., 1.))\n",
    "        assert raw_mu_b_T.shape == (S,)\n",
    "\n",
    "    with pyro.plate(\"raw_mu_b_x-asis\", size = S):\n",
    "        with pyro.plate(\"raw_mu_b_y-plate\", size = T):\n",
    "           raw_mu_b = pyro.sample(\"mu_b_T\", dist.Normal(0., 1.)) \n",
    "           raw_mu_b.t().flatten() #Matrix to Column Order Vector\n",
    "    \n",
    "    with pyro.plate(\"raw_mu_c-plate\", size = P):\n",
    "        raw_mu_c = pyro.sample(\"raw_mu_c\", dist.Normal(0., 1.))\n",
    "\n",
    "    with pyro.plate(\"raw_mu_m-plate\", size = M):\n",
    "        raw_mu_m = pyro.sample(\"mu_m\", dist.Normal(0., 1.))\n",
    "\n",
    "    with pyro.plate(\"raw_mu_pop-plate\", size = Pop):\n",
    "        raw_mu_pop = pyro.sample(\"raw_mu_pop\", dist.Normal(0., 1.))\n",
    "\n",
    "    #!Not sure if this satisfies Offset=0 and multiplier=0.02\n",
    "    mu_e_bias = pyro.sample(\"mu_e_bias\", dist.Normal(0., 0.02))*0.02 \n",
    "\n",
    "    #!Need to find way to add constraint lower = 0, upper = 1\n",
    "    rho_e_bias = pyro.sample(\"rho_e_bias\", dist.Normal(0.7, 0.1)) \n",
    "\n",
    "    with pyro.plate(\"raw_e_bias-plate\", size = T):\n",
    "        raw_e_bias = pyro.sample(\"raw_e_bias\", dist.Normal(0., 1.))\n",
    "\n",
    "    with pyro.plate(\"raw_measure_noise_national-plate\", size = N_national_polls):\n",
    "        raw_measure_noise_national = pyro.sample(\"measure_noise_national\", dist.Normal(0., 1.))\n",
    "    \n",
    "    with pyro.plate(\"raw_measure_noise_state-plate\", size = N_state_polls):\n",
    "        raw_measure_noise_state = pyro.sample(\"measure_noise_state\", dist.Normal(0., 1.))\n",
    "\n",
    "    with pyro.plate(\"raw_polling_bias-plate\", size = S):\n",
    "        raw_polling_bias = pyro.sample(\"polling_bias\", dist.Normal(0., 1.))\n",
    "\n",
    "    #Transformed Parameters\n",
    "    mu_b = pyro.param('mu_b', torch.empty(S, T)) #initalize mu_b\n",
    "    mu_b[:,T] = cholesky_ss_cov_mu_b_T @ raw_mu_b_T + mu_b_prior\n",
    "    for i in range(1,T):\n",
    "        mu_b[:, T - i] = cholesky_ss_cov_mu_b_walk @ raw_mu_b[:, T - i] + mu_b[:, T + 1 - i]\n",
    "    \n",
    "    mu_c = pyro.param('mu_c', raw_mu_c * sigma_c)\n",
    "    mu_m = pyro.param('mu_m', raw_mu_m * sigma_m)\n",
    "    mu_pop = pyro.param('mu_pop', raw_mu_pop * sigma_pop)\n",
    "    sigma_rho = pyro.param('sigma_rho', torch.sqrt(1-(rho_e_bias)**2) * sigma_e_bias)\n",
    "\n",
    "    e_bias = pyro.param('e_bias', torch.empty(T)) #initalize e_bias\n",
    "    e_bias[1] = raw_e_bias[1] * sigma_e_bias\n",
    "    for t in range(2,T+1):\n",
    "        e_bias[t] = mu_e_bias + rho_e_bias * (e_bias[t - 1] - mu_e_bias) + raw_e_bias[t] * sigma_rho\n",
    "\n",
    "    polling_bias = pyro.param('polling_bias', cholesky_ss_cov_poll_bias @ raw_polling_bias)\n",
    "    national_mu_b_average = pyro.param('national_mu_b_average', mu_b.t() @ state_weights)\n",
    "    national_polling_bias_average = pyro.param('national_polling_bias_average', polling_bias.T @ state_weights)\n",
    "\n",
    "    logit_pi_democrat_state = pyro.param('logit_pi_democrat_state', torch.empty(N_state_polls))\n",
    "    logit_pi_democrat_national = pyro.param('logit_pi_democrat_national', torch.empty(N_national_polls))\n",
    "\n",
    "    for i in range(1,N_state_polls+1):\n",
    "        logit_pi_democrat_state[i] = mu_b[state[i], day_state[i]] + mu_c[poll_state[i]] + mu_m[poll_mode_state[i]] + \\\n",
    "            mu_pop[poll_pop_state[i]] + unadjusted_state[i] * e_bias[day_state[i]] + raw_measure_noise_state[i] * sigma_measure_noise_state + \\\n",
    "            polling_bias[state[i]]\n",
    "  \n",
    "    logit_pi_democrat_national = national_mu_b_average[day_national] +  mu_c[poll_national] + mu_m[poll_mode_national] + \\\n",
    "        mu_pop[poll_pop_national] + unadjusted_national * e_bias[day_national] + raw_measure_noise_national * sigma_measure_noise_national +\\\n",
    "        national_polling_bias_average\n",
    "    \n",
    "    #Likelihood Of the Model\n",
    "    #!need to verify if this is the correct implementation for binomial_logit of stan\n",
    "    with pyro.plate(\"state-data-plate\", size = N_state_polls):\n",
    "        pyro.sample(\"n_democrat_state\", dist.Binomial(n_two_share_state, logits = logit_pi_democrat_state), obs = n_democrat_state)\n",
    "    \n",
    "    with pyro.plate(\"national-data-plate\", size = N_national_polls):\n",
    "        pyro.sample(\"n_democrat_national\", dist.Binomial(n_two_share_national, logits = logit_pi_democrat_national), obs = n_democrat_national)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!Need to modify this based on hyper-parameters used by the Original Model\n",
    "def Inference_MCMC(model, data, polls, n_samples = 500, n_warmup = 500, n_chains = 6):\n",
    "    nuts_kernel = NUTS(model)\n",
    "    mcmc = MCMC(nuts_kernel, num_samples = n_samples, warmup_steps = n_warmup, num_chains = n_chains)\n",
    "    mcmc.run(data, polls)\n",
    "    posterior_samples = mcmc.get_samples()\n",
    "\n",
    "    hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}\n",
    "\n",
    "    return posterior_samples, hmc_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate samples from posterior predictive distribution\n",
    "def sample_posterior_predictive(model, posterior_samples, n_samples, data):\n",
    "    posterior_predictive = Predictive(model, posterior_samples, num_samples = n_samples)\n",
    "    posterior_predictive_samples = posterior_predictive.get_samples(data, None)\n",
    "\n",
    "    return posterior_predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Quantity from posterior sample\n",
    "def predicted_score(model, posterior_samples, data):\n",
    "    T = data['T']\n",
    "    S = data['S']\n",
    "    predicted = torch.empty(T, S)\n",
    "    posterior_predictive = Predictive(model, posterior_samples)\n",
    "    trace  = posterior_predictive.get_vectorized_trace(data)\n",
    "    \n",
    "    print(trace.nodes.keys())\n",
    "    mu_b = trace.nodes['mu_b']\n",
    "    print(mu_b)\n",
    "    #for s in range(1,S+1):\n",
    "     #   predicted[:,s] = expit(mu_b[s,:].t().flatten())\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016, 'black_pct', 'college_pct', 'hisp_other_pct', 'median_age', 'pct_white_evangel', 'pop_density', 'white_pct', 'wwc_pct'] [0.2162890087639303, 0.00396169583885996, 0.139747908727421, 0.0422148218437831, 30.5, 0.02923107672064036, 9.108415574117505, 0.222308740920812, 0.0250285919948363]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                incvote   R-squared:                       0.770\n",
      "Model:                            OLS   Adj. R-squared:                  0.740\n",
      "Method:                 Least Squares   F-statistic:                     25.15\n",
      "Date:                Mon, 16 Nov 2020   Prob (F-statistic):           1.62e-05\n",
      "Time:                        17:26:35   Log-Likelihood:                -41.736\n",
      "No. Observations:                  18   AIC:                             89.47\n",
      "Df Residuals:                      15   BIC:                             92.14\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     49.6070      0.835     59.386      0.000      47.826      51.387\n",
      "juneapp        0.1393      0.027      5.183      0.000       0.082       0.197\n",
      "q2gdp          0.4480      0.164      2.738      0.015       0.099       0.797\n",
      "==============================================================================\n",
      "Omnibus:                        0.072   Durbin-Watson:                   2.417\n",
      "Prob(Omnibus):                  0.965   Jarque-Bera (JB):                0.289\n",
      "Skew:                          -0.072   Prob(JB):                        0.865\n",
      "Kurtosis:                       2.396   Cond. No.                         34.4\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-31043a55366b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpass_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-bd4666a7ccc1>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(data, polls)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m#Transformed Parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mmu_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mu_b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#initalize mu_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mmu_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcholesky_ss_cov_mu_b_T\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mraw_mu_b_T\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmu_b_prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mmu_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcholesky_ss_cov_mu_b_walk\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mraw_mu_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmu_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "data, polls = pass_data()\n",
    "model(data, polls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
